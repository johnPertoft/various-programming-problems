{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "18.1 Write a function that adds two numbers. You should not use + or any arithmetic\n",
    "operators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add(a, b):\n",
    "    assert a >= 0 and b >= 0\n",
    "    aa, bb = a, b\n",
    "    res = 0\n",
    "    carry_bit = 0\n",
    "    i = 1 # Holds a 1 at current bit position\n",
    "    while aa or bb or carry_bit:\n",
    "        ai = (a & i)\n",
    "        bi = (b & i)\n",
    "        if ai and bi and carry_bit:\n",
    "            # Set a 1 at this position and carry over a 1\n",
    "            res = res | i\n",
    "            carry_bit = 1\n",
    "        elif (ai and bi) or ((ai ^ bi) and carry_bit):\n",
    "            # Keep a 0 at this position but carry over a 1\n",
    "            carry_bit = 1\n",
    "        elif (ai ^ bi) or carry_bit:\n",
    "            # Set a 1 at this position\n",
    "            res = res | i\n",
    "            carry_bit = 0\n",
    "        i = i << 1\n",
    "        aa = aa >> 1\n",
    "        bb = bb >> 1\n",
    "    return res\n",
    "\n",
    "assert add(13, 37) == 50\n",
    "assert add(37, 13) == 50\n",
    "assert add(10, 0) == 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18.2 Write a method to shuffle a deck of cards. It must be a perfect shuffleâ€”in other\n",
    "words, each of the 52! permutations of the deck has to be equally likely. Assume\n",
    "that you are given a random number generator which is perfect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41, 19, 24, 37, 48, 18, 23, 15, 36, 1, 9, 28, 38, 0, 44, 50, 29, 7, 51, 39, 43, 26, 42, 16, 10, 40, 3, 20, 47, 14, 27, 22, 11, 30, 33, 46, 21, 35, 49, 5, 4, 6, 12, 45, 17, 8, 2, 34, 13, 31, 25, 32]\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "\n",
    "# O(n^2)\n",
    "def shuffle_deck_naive():\n",
    "    deck = list(range(52))\n",
    "    shuffled_deck = []\n",
    "    while deck:\n",
    "        shuffled_deck.append(deck.pop(randint(0, len(deck) - 1)))\n",
    "    return shuffled_deck\n",
    "\n",
    "# O(n), Fisher-Yates algorithm (Really same as above but smarter)\n",
    "# i.e. first pick from whole range, then pick from everything except the picked one\n",
    "# and so on.\n",
    "def shuffle_deck():\n",
    "    deck = list(range(52))\n",
    "    for i in range(51, 0, -1):\n",
    "        j = randint(0, i)\n",
    "        deck[i], deck[j] = deck[j], deck[i] # Swap them\n",
    "    return deck\n",
    "        \n",
    "# TODO: how to test?\n",
    "print(shuffle_deck())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18.3 Write a method to randomly generates set of m integers from an array of size n.\n",
    "Each element must have equal probability of being chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23, 73, 90, 38, 85, 15, 7, 69, 92, 78]\n",
      "[58, 76, 96, 77, 0, 14, 3, 13, 99, 40]\n",
      "[92, 88, 43, 2, 19, 71, 57, 50, 62, 28]\n",
      "[58, 61, 93, 74, 44, 28, 42, 86, 3, 20]\n",
      "[7, 22, 38, 76, 72, 53, 91, 32, 34, 70]\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "\n",
    "# Using same idea as shuffle, but only running m steps\n",
    "# Q: Should it be an actual set? what if A contains same element more than once?\n",
    "def random_set(A, m):\n",
    "    assert m <= len(A)\n",
    "    S = A[:]\n",
    "    for i in range(min(len(S)-1, m)):\n",
    "        j = randint(i, len(S)-1)\n",
    "        S[i], S[j] = S[j], S[i]\n",
    "    return S[:m]\n",
    "\n",
    "for _ in range(5):\n",
    "    print(random_set(list(range(100)), 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18.4 Write a method to count the number of 2s that appear in all the numbers\n",
    "between 0 and n (inclusive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 1, 3, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "def _num_2s_in(n):\n",
    "    num_2s = 0\n",
    "    while n:\n",
    "        if n % 10 == 2:\n",
    "            num_2s += 1\n",
    "        n = n // 10\n",
    "    return num_2s\n",
    "\n",
    "def count_2s_naive(n):\n",
    "    num_2s = 0\n",
    "    while n:\n",
    "        num_2s += _num_2s_in(n)\n",
    "        n -= 1\n",
    "    return num_2s\n",
    "\n",
    "# TODO: something with counting how many number have a 2 at digit d?\n",
    "def count_2s(n):\n",
    "    digits = []\n",
    "    x = n\n",
    "    while x:\n",
    "        digits.append(x % 10)\n",
    "        x = x // 10\n",
    "    \n",
    "    num_2s = 0\n",
    "    for digit in digits:\n",
    "        if digit == 2:\n",
    "            pass\n",
    "        elif digit < 2:\n",
    "            pass\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    return num_2s\n",
    "\n",
    "#assert count_2s(2) == 1\n",
    "#assert count_2s(10) == 1\n",
    "#assert count_2s(20) == 3 # 2, 12, 20\n",
    "#assert count_2s(22) == 6 # 2, 12, 20, 21, 22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "18.5 You have a large text file containing words. Given any two words, find the shortest\n",
    "distance (in terms of number of words) between them in the file. If the operation\n",
    "will be repeated many times for the same file (but different pairs of words), can you\n",
    "optimize your solution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to /home/john/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming order of word1 and word2 does not matter.\n",
    "# O(n)\n",
    "def shortest_distance(text, word1, word2):\n",
    "    last_word1_pos, last_word2_pos = -1, -1\n",
    "    min_distance = float(\"inf\")\n",
    "    for i, word in enumerate(text):\n",
    "        if word == word1:\n",
    "            if last_word2_pos >= 0:\n",
    "                d = i - last_word2_pos\n",
    "                min_distance = min(min_distance, d)\n",
    "            last_word1_pos = i\n",
    "        elif word == word2:\n",
    "            if last_word1_pos >= 0:\n",
    "                d = i - last_word1_pos\n",
    "                min_distance = min(min_distance, d)\n",
    "            last_word2_pos = i\n",
    "        if min_distance == 1: # Early exit, can't be closer than one\n",
    "            return min_distance\n",
    "    return min_distance\n",
    "\n",
    "import nltk\n",
    "nltk.download(\"gutenberg\")\n",
    "hamlet = nltk.corpus.gutenberg.words('shakespeare-hamlet.txt')\n",
    "\n",
    "assert shortest_distance(hamlet, \"William\", \"Shakespeare\") == 1\n",
    "\n",
    "shortest_distance(hamlet, \"Claudius\", \"Gertrude\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Follow up question, repeated queries for same file\n",
    "from collections import defaultdict\n",
    "\n",
    "def index_corpus(text):\n",
    "    word_positions = defaultdict(list)\n",
    "    for i, word in enumerate(text):\n",
    "        word_positions[word].append(i)\n",
    "    return word_positions\n",
    "\n",
    "def shortest_distance(index, word1, word2):\n",
    "    word1_positions = index[word1]\n",
    "    word2_positions = index[word2]\n",
    "    if not word1_positions or not word2_positions:\n",
    "        return -1\n",
    "    last_word1_pos = -1\n",
    "    last_word2_pos = -1\n",
    "    i, j = 0, 0\n",
    "    min_distance = float(\"inf\")\n",
    "    while i < len(word1_positions) and j < len(word2_positions):\n",
    "        if word1_positions[i] < word2_positions[j]:\n",
    "            if last_word2_pos >= 0:\n",
    "                d = word1_positions[i] - last_word2_pos\n",
    "                min_distance = min(d, min_distance)\n",
    "                \n",
    "            last_word1_pos = word1_positions[i]\n",
    "            i += 1\n",
    "        else:\n",
    "            if last_word1_pos >= 0:\n",
    "                d = word2_positions[j] - last_word1_pos\n",
    "                min_distance = min(d, min_distance)\n",
    "        \n",
    "            last_word2_pos = word2_positions[j]\n",
    "            j += 1\n",
    "    # Take care of the remaining list but only need to check first since\n",
    "    # the rest will give a bigger distance anyway.\n",
    "    if i < len(word1_positions):\n",
    "        d = word1_positions[i] - last_word2_pos\n",
    "        min_distance = min(d, min_distance)\n",
    "    elif j < len(word2_positions):\n",
    "        d = word2_positions[j] - last_word1_pos\n",
    "        min_distance = min(d, min_distance)\n",
    "    \n",
    "    return min_distance\n",
    "    \n",
    "index = index_corpus(nltk.corpus.gutenberg.words('shakespeare-hamlet.txt'))\n",
    "assert shortest_distance(index, \"William\", \"Shakespeare\") == 1\n",
    "shortest_distance(index, \"Claudius\", \"Gertrude\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "18.6 Describe an algorithm to find the smallest one million numbers in one billion\n",
    "numbers. Assume that the computer memory can hold all one billion numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smallest_k_numbers_naive 0.5388686335001693\n",
      "smallest_k_numbers_heap1 0.06590161109998008\n",
      "smallest_k_numbers_heap2 0.814148533900152\n"
     ]
    }
   ],
   "source": [
    "from heapq import heappush, heappop, heapify\n",
    "\n",
    "# O(n log(n))\n",
    "def smallest_k_numbers_naive(A, k):\n",
    "    return sorted(A)[:k]\n",
    "\n",
    "# O(n) + O(k log(n))??\n",
    "def smallest_k_numbers_heap1(A, k):\n",
    "    heapify(A) # O(n)\n",
    "    return [heappop(A) for _ in range(min(k, len(A)))] # O(k log(n))\n",
    "\n",
    "max_heappush = lambda h, x: heappush(h, -x)\n",
    "max_heappop = lambda h: -heappop(h)\n",
    "    \n",
    "def smallest_k_numbers_heap2(A, k):\n",
    "    assert len(A) > k\n",
    "    h = []\n",
    "    for i in range(k):\n",
    "        max_heappush(h, A[i])\n",
    "    for i in range(k, len(A)):\n",
    "        # Push the next and remove the largest\n",
    "        max_heappush(h, A[i])\n",
    "        max_heappop(h)\n",
    "    # NOTE: just returning the smallest k numbers, they are not sorted though \n",
    "    # since it was not required\n",
    "    return [-x for x in h]\n",
    "    \n",
    "def smallest_k_numbers_selection_rank(A, k):\n",
    "    pass # TODO\n",
    "    \n",
    "from random import randint\n",
    "from utils import timeit_and_return\n",
    "A = [randint(0, int(1e9)) for _ in range(int(1e6))]\n",
    "k = 10000\n",
    "naive, t0 = timeit_and_return(lambda: smallest_k_numbers_naive(A[:], k))\n",
    "heap1, t1 = timeit_and_return(lambda: smallest_k_numbers_heap1(A[:], k))\n",
    "heap2, t2 = timeit_and_return(lambda: smallest_k_numbers_heap2(A[:], k))\n",
    "\n",
    "print(smallest_k_numbers_naive.__name__, t0)\n",
    "print(smallest_k_numbers_heap1.__name__, t1)\n",
    "print(smallest_k_numbers_heap2.__name__, t2)\n",
    "\n",
    "assert naive == heap1 == sorted(heap2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18.7 Given a list of words, write a program to find the longest word made of other words\n",
    "in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /home/john/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'formaldehydesulphoxylate'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ok to have a word more than once in a composite word, should be fine with this anyway?\n",
    "\n",
    "def longest_composite_word(A):\n",
    "    all_words = set(A)\n",
    "    A.sort(key=lambda s: len(s), reverse=True)\n",
    "    mem = {}\n",
    "    def is_composite(w):\n",
    "        if w in all_words:\n",
    "            return True\n",
    "        if w in mem:\n",
    "            return True\n",
    "        # Try splitting at different indexes and see if they form composites\n",
    "        for i in range(1, len(w)):\n",
    "            w1 = w[:i]\n",
    "            if w1 in all_words and is_composite(w[i:]):\n",
    "                mem[w] = True\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    for w in A:\n",
    "        for i in range(1, len(w)):\n",
    "            w1 = w[:i]\n",
    "            if w1 in all_words and is_composite(w[i:]):\n",
    "                return w\n",
    "    return None\n",
    "            \n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import words\n",
    "nltk.download(\"words\")\n",
    "english_words = words.words()\n",
    "\n",
    "#longest_composite_word(english_words)\n",
    "english_words_no_single_letters = [w for w in english_words if len(w) > 1]\n",
    "longest_composite_word(english_words_no_single_letters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18.8 Given a string s and an array of smaller strings T, design a method to search s for\n",
    "each small string in T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /home/john/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "search_naive 0.15069439470025828\n",
      "search_hashmap 0.28825892679997195\n",
      "search_parallel 0.1177900047001458\n",
      "search_suffix_tree 0.33182902189983\n"
     ]
    }
   ],
   "source": [
    "# Q: What should be returned? the t's that are in s?\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "def search_naive(s, T):\n",
    "    hits = deque()\n",
    "    for t in T:\n",
    "        if t in s:\n",
    "            hits.append(t)\n",
    "    return hits\n",
    "\n",
    "from multiprocessing import Process, Queue, cpu_count          \n",
    "\n",
    "def search_parallel(s, T):\n",
    "    hits = Queue()\n",
    "    \n",
    "    # Compute chunk sizes of T for workers\n",
    "    num_processes = cpu_count()\n",
    "    chunk_sizes = [len(T) // num_processes] * num_processes\n",
    "    remaining = len(T) - chunk_sizes[0] * num_processes\n",
    "    i = 0\n",
    "    while remaining:\n",
    "        chunk_sizes[i] += 1\n",
    "        remaining -= 1\n",
    "        i += 1\n",
    "    \n",
    "    # Worker function\n",
    "    def f(q, start, end):\n",
    "        for i in range(start, end):\n",
    "            if T[i] in s:\n",
    "                q.put(T[i])\n",
    "    \n",
    "    # Start processes to deal with each chunk\n",
    "    processes = [None] * num_processes\n",
    "    start = 0\n",
    "    end = 0\n",
    "    for i in range(num_processes):\n",
    "        end += chunk_sizes[i]\n",
    "        p = Process(target=f, args=(hits, start, end))\n",
    "        processes[i] = p\n",
    "        p.start()\n",
    "        start += chunk_sizes[i]\n",
    "    \n",
    "    # Let each process finish\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "    \n",
    "    # Queue is not iterable apparently so need this extra step\n",
    "    return [hits.get() for _ in range(hits.qsize())] \n",
    "\n",
    "def search_hashmap(s, T):\n",
    "    hits = deque()\n",
    "    substrings = {}\n",
    "    # Precompute all possible substrings for fast lookup\n",
    "    for i in range(len(s)):\n",
    "        for j in range(i+1, len(s)+1): # TODO: correct?\n",
    "            substrings[s[i:j]] = True\n",
    "    for t in T:\n",
    "        if t in substrings:\n",
    "            hits.append(t)\n",
    "    return hits\n",
    "            \n",
    "class SuffixTreeNode:\n",
    "    def __init__(self):\n",
    "        self.char = None\n",
    "        self.children = {}\n",
    "    def insert(self, s): # Should we save indexes too?\n",
    "        if not s:\n",
    "            return\n",
    "        c = s[0]\n",
    "        if not c in self.children:\n",
    "            self.children[c] = SuffixTreeNode()\n",
    "        return self.children[c].insert(s[1:])\n",
    "    def __contains__(self, t):\n",
    "        if not t:\n",
    "            return True\n",
    "        c = t[0]\n",
    "        if c not in self.children:\n",
    "            return False\n",
    "        return t[1:] in self.children[c]\n",
    "\n",
    "def _construct_suffix_tree(s):\n",
    "    suffix_tree = SuffixTreeNode()\n",
    "    for i in range(len(s)):\n",
    "        suffix_tree.insert(s[i:])\n",
    "    return suffix_tree\n",
    "    \n",
    "def search_suffix_tree(suffix_tree, T):   \n",
    "    hits = deque()\n",
    "    for t in T:\n",
    "        if t in suffix_tree:\n",
    "            hits.append(t)\n",
    "    return hits\n",
    "\n",
    "from random import randint\n",
    "import nltk\n",
    "from nltk.corpus import words\n",
    "from utils import timeit_and_return\n",
    "nltk.download(\"words\")\n",
    "T = list(map(lambda w: w.lower(), words.words()))\n",
    "s = \"\".join(T[randint(0, len(T))] for _ in range(100)).lower()\n",
    "\n",
    "suffix_tree = _construct_suffix_tree(s)\n",
    "\n",
    "# TODO: Hmm, why is the suffix tree slowest here?\n",
    "\n",
    "naive, t_naive = timeit_and_return(lambda: search_naive(s, T))\n",
    "hashmap, t_hashmap = timeit_and_return(lambda: search_hashmap(s, T))\n",
    "parallel, t_parallel = timeit_and_return(lambda: search_parallel(s, T))\n",
    "suffix_tree_res, t_suffix = timeit_and_return(lambda: search_suffix_tree(suffix_tree, T))\n",
    "print(search_naive.__name__, t_naive)\n",
    "print(search_hashmap.__name__, t_hashmap)\n",
    "print(search_parallel.__name__, t_parallel)\n",
    "print(search_suffix_tree.__name__, t_suffix)\n",
    "assert set(naive) == set(hashmap) == set(parallel) == set(suffix_tree_res) # Use set here since parallel may not be ordered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "18.9 Numbers are randomly generated and passed to a method. Write a program to find\n",
    "and maintain the median value as new values are generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from heapq import heappush, heappop\n",
    "\n",
    "class MedianMaintainer:\n",
    "    def __init__(self):\n",
    "        self.max_heap = []\n",
    "        self.min_heap = []\n",
    "        self.max_heappush = lambda x: heappush(self.max_heap, -x)\n",
    "        self.max_heappop = lambda: -heappop(self.max_heap)\n",
    "        self.min_heappush = lambda x: heappush(self.min_heap, x)\n",
    "        self.min_heappop = lambda: heappop(self.min_heap)\n",
    "        self.current_median = None\n",
    "    def update_and_get(self, x):\n",
    "        \"\"\"Update the median so far with the given x by updating a max heap and a min heap.\n",
    "        The max heap stores all elements below and equal to the median and the min heap \n",
    "        stores all elements above the median\n",
    "        \"\"\"\n",
    "        \n",
    "        # Invariant here is that the length of the max_heap is always the same or one element\n",
    "        # bigger than the length of the min_heap.\n",
    "        \n",
    "        # Add x to correct heap\n",
    "        if not self.current_median or x <= self.current_median:\n",
    "            self.max_heappush(x)\n",
    "        else:\n",
    "            self.min_heappush(x)\n",
    "        \n",
    "        # Rebalance heaps\n",
    "        if len(self.max_heap) - len(self.min_heap) > 1:\n",
    "            self.min_heappush(self.max_heappop())\n",
    "        elif len(self.min_heap) > len(self.max_heap):\n",
    "            self.max_heappush(self.min_heappop())\n",
    "        \n",
    "        # Return the middle element or the average of the two middle elements\n",
    "        # if even number of elements seen.\n",
    "        if len(self.max_heap) > len(self.min_heap):\n",
    "            self.current_median = -self.max_heap[0]\n",
    "        else:\n",
    "            a = -self.max_heap[0]\n",
    "            b = self.min_heap[0]\n",
    "            self.current_median = (a + b) / 2\n",
    "        return self.current_median\n",
    "\n",
    "def median_definition(A):\n",
    "    A.sort()\n",
    "    if len(A) % 2 == 1:\n",
    "        return A[len(A) // 2]\n",
    "    else:\n",
    "        i = len(A) // 2\n",
    "        return (A[i] + A[i-1]) / 2\n",
    "\n",
    "from random import randint\n",
    "A = []\n",
    "median_maintainer = MedianMaintainer()\n",
    "for _ in range(1000):\n",
    "    x = randint(0, int(1e4))\n",
    "    A.append(x)\n",
    "    assert median_maintainer.update_and_get(x) == median_definition(A)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "18.10 Given two words of equal length that are in a dictionary, write a method to transform one word into another word by changing only one letter at a time. The new\n",
    "word you get in each step must be in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /home/john/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "deque(['coke', 'cole', 'cola'])\n",
      "deque(['slow', 'slot', 'flot', 'fiot', 'fist', 'fast'])\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "import string\n",
    "\n",
    "def transform_word(word1, word2, dictionary):\n",
    "    \"\"\"Use a BFS to traverse the implicit \"word edit\" graph which gives the\n",
    "    shortest edit distance between the given words\"\"\"\n",
    "    assert len(word1) == len(word2)\n",
    "    assert word1 in dictionary and word2 in dictionary\n",
    "    \n",
    "    # O(na) where a is length of alphabet and n is length of word\n",
    "    def neighbor_words(word):\n",
    "        neighbors = set()\n",
    "        for i in range(len(word)):\n",
    "            for c in string.ascii_lowercase: # a-z\n",
    "                new_word = word[:i] + c + word[i+1:]\n",
    "                if new_word in dictionary:\n",
    "                    neighbors.add(new_word)\n",
    "        return neighbors\n",
    "    \n",
    "    discovered = {}\n",
    "    parent = {}\n",
    "    q = deque()\n",
    "    q.append(word1)\n",
    "    parent[word1] = None\n",
    "    discovered[word1] = True\n",
    "    while q:\n",
    "        word = q.popleft()\n",
    "        if word == word2:\n",
    "            # Print the transformation path\n",
    "            w = word\n",
    "            path = deque()\n",
    "            while parent[w]:\n",
    "                path.appendleft(w)\n",
    "                w = parent[w]\n",
    "            path.appendleft(w)\n",
    "            return path\n",
    "        for w in neighbor_words(word):\n",
    "            if w not in discovered:\n",
    "                parent[w] = word\n",
    "                q.append(w)\n",
    "                discovered[w] = True\n",
    "    \n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import words\n",
    "nltk.download(\"words\")\n",
    "dictionary = set(w.lower() for w in words.words())\n",
    "\n",
    "def test_transform_word(path, dictionary):\n",
    "    prev = None\n",
    "    for p in path:\n",
    "        assert p in dictionary\n",
    "        if prev:\n",
    "            assert len(p) == len(prev)\n",
    "            d = sum(1 if c1 != c2 else 0 for c1, c2 in zip(list(p), list(prev)))\n",
    "            assert d == 1 # Should be just one changed letter\n",
    "        prev = p\n",
    "        \n",
    "transformation_path1 = transform_word(\"coke\", \"cola\", dictionary) # coke - cole - cola\n",
    "transformation_path2 = transform_word(\"slow\", \"fast\", dictionary)\n",
    "print(transformation_path1)  \n",
    "print(transformation_path2)\n",
    "\n",
    "test_transform_word(transformation_path1, dictionary)\n",
    "test_transform_word(transformation_path2, dictionary)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18.11 Imagine you have a square matrix, where each cell (pixel) is either black or white.\n",
    "Design an algorithm to find the maximum subsquare such that all four borders are\n",
    "filled with black pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Q: Should subsquares enclosed by one side of the big square count? I.e. if the right side is shared\n",
    "# with the right edge of the whole matrix and thus has no edge of black pixels on the right side.\n",
    "# Also should the borders count towards the area?\n",
    "# Q: If a black pixel is inside a subsquare, should the subsquare still count? Assuming yes here.\n",
    "\n",
    "def maximum_subsquare(A):\n",
    "    assert len(A) == len(A[0]) # Only squares\n",
    "    N = len(A)\n",
    "    \n",
    "    # Precompute contigious length ranges of black pixels\n",
    "    down = [r[:] for r in [[0] * N] * N]\n",
    "    right = [r[:] for r in [[0] * N] * N]\n",
    "    for r in range(N-1, -1, -1):\n",
    "        right[r][N-1] = A[r][N-1]\n",
    "        for c in range(N-2, -1, -1):\n",
    "            right[r][c] = 0 if A[r][c] == 0 else A[r][c] + right[r][c+1]\n",
    "    for c in range(N-1, -1, -1):\n",
    "        down[N-1][c] = A[N-1][c]\n",
    "        for r in range(N-2, -1, -1):\n",
    "            down[r][c] = 0 if A[r][c] == 0 else A[r][c] + down[r+1][c]\n",
    "\n",
    "    # O(n^2)\n",
    "    def subsquare_exists(square_size):\n",
    "        for r in range(N - square_size + 1):\n",
    "            for c in range(N - square_size + 1):\n",
    "                top_and_bottom = right[r][c] == square_size and right[r+square_size-1][c] == square_size\n",
    "                left_and_right = down[r][c] == square_size and down[r][c+square_size-1] == square_size\n",
    "                if top_and_bottom and left_and_right:\n",
    "                    return True\n",
    "        return False\n",
    "           \n",
    "    # O(n^3)\n",
    "    for square_size in range(N, 0, -1):\n",
    "        if subsquare_exists(square_size):\n",
    "            return square_size * square_size\n",
    "            \n",
    "    return -1\n",
    "\n",
    "A1 = [[0, 0, 0, 0, 0],\n",
    "      [1, 1, 1, 1, 0],\n",
    "      [1, 0, 0, 1, 0],\n",
    "      [1, 0, 0, 1, 0],\n",
    "      [1, 1, 1, 1, 0]]\n",
    "\n",
    "A2 = [[0, 0, 0, 0, 0],\n",
    "      [1, 1, 1, 1, 0],\n",
    "      [1, 0, 0, 1, 0],\n",
    "      [1, 0, 0, 0, 0],\n",
    "      [1, 1, 1, 1, 0]]\n",
    "\n",
    "A3 = [[0, 0, 0, 0, 0],\n",
    "      [0, 0, 0, 0, 0],\n",
    "      [0, 0, 0, 0, 0],\n",
    "      [0, 0, 0, 0, 0],\n",
    "      [0, 0, 0, 0, 0]]\n",
    "\n",
    "assert maximum_subsquare(A1) == 16\n",
    "assert maximum_subsquare(A2) == 1 # If we have at least one black pixel the answer should be at least 1\n",
    "assert maximum_subsquare(A3) == -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18.12 Given an NxN matrix of positive and negative integers, write code to find the submatrix with the largest possible sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# O(n^4)\n",
    "def largest_sum_submatrix(A):\n",
    "    assert len(A) == len(A[0])\n",
    "    N = len(A)\n",
    "    # Compute cumulative sum of elements from bottomw right\n",
    "    # going up to top left with padded zeros on right and bottom.\n",
    "    cumsum = [r[:] for r in [[0] * (N+1)] * (N+1)]\n",
    "    cumsum[N-1][N-1] = A[N-1][N-1]\n",
    "    for r in range(N-2, -1, -1):\n",
    "        cumsum[r][N-1] = A[r][N-1] + cumsum[r+1][N-1]\n",
    "    for c in range(N-2, -1, -1):\n",
    "        cumsum[N-1][c] = A[N-1][c] + cumsum[N-1][c+1]\n",
    "    for r in range(N-2, -1, -1):\n",
    "        for c in range(N-2, -1, -1):\n",
    "            cumsum[r][c] = A[r][c] + cumsum[r+1][c] + cumsum[r][c+1] - cumsum[r+1][c+1]\n",
    "    \n",
    "    largest_sum = float(\"-inf\")\n",
    "    largest_submatrix = (-1, -1, -1, -1)\n",
    "    for r1 in range(N): # TODO: what should these ranges be? could pad cumsum matrix with extra border of zeros\n",
    "        for c1 in range(N):\n",
    "            for r2 in range(r1, N):\n",
    "                for c2 in range(c1, N):\n",
    "                    # ---------\n",
    "                    # |_A_|_B_|\n",
    "                    # |_C_|_D_|\n",
    "                    # sum(A) = cumsum(A) - cumsum(B) - cumsum(C) + cumsum(D)\n",
    "                    A = cumsum[r1][c1]\n",
    "                    B = cumsum[r1][c2+1]\n",
    "                    C = cumsum[r2+1][c1]\n",
    "                    D = cumsum[r2+1][c2+1]\n",
    "                    m_sum = A - B - C + D\n",
    "                    if m_sum > largest_sum:\n",
    "                        largest_sum = m_sum\n",
    "                        largest_submatrix = (r1, c1, r2, c2)\n",
    "    \n",
    "    return largest_sum, largest_submatrix\n",
    "    \n",
    "# O(n^3)\n",
    "def largest_sum_submatrix2(A):\n",
    "    assert len(A) == len(A[0])\n",
    "    N = len(A)\n",
    "    largest_sum = float(\"-inf\")\n",
    "    \n",
    "    # Try all different pairs of top and bottom rows and do dp\n",
    "    # inside these\n",
    "    for r1 in range(N):\n",
    "        cumsum = [0] * N\n",
    "        for r2 in range(r1, N):\n",
    "            for c in range(N):\n",
    "                cumsum[c] += A[r2][c]\n",
    "            \n",
    "            # The elements of cumsum are the cumulative sums of columns in A\n",
    "            # between rows r1 and r2 so now it's just largest subarray problem.\n",
    "            current_submatrix_sum = 0\n",
    "            current_max = 0\n",
    "            for x in cumsum:\n",
    "                # Either continue on same submatrix or start new\n",
    "                current_submatrix_sum = max(0, current_submatrix_sum + x) \n",
    "                current_max = max(current_max, current_submatrix_sum)\n",
    "            \n",
    "            largest_sum = max(largest_sum, current_max)\n",
    "    \n",
    "    return largest_sum\n",
    "\n",
    "A = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "largest_sum_submatrix2(A)\n",
    "\n",
    "# TODO: tests for both these"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "18.13 Given a list of millions of words, design an algorithm to create the largest possible\n",
    "rectangle of letters such that every row forms a word (reading left to right) and\n",
    "every column forms a word (reading top to bottom). The words need not be chosen\n",
    "consecutively from the list, but all rows must be the same length and all columns\n",
    "must be the same height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /home/john/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "Trying rectangle of size 22(w) x 22(h)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-c625d7e40c7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time word_rectangle(dictionary)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/john/opt/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m   2156\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2157\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2158\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2160\u001b[0m     \u001b[0;31m#-------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/john/opt/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line)\u001b[0m\n\u001b[1;32m   2077\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2078\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2079\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2080\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-59>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/home/john/opt/anaconda3/lib/python3.5/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/john/opt/anaconda3/lib/python3.5/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'eval'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-57-c625d7e40c7d>\u001b[0m in \u001b[0;36mword_rectangle\u001b[0;34m(dictionary)\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mwr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_word_rectangle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords_by_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-57-c625d7e40c7d>\u001b[0m in \u001b[0;36m_word_rectangle\u001b[0;34m(width, height, words_by_size)\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;31m# valid prefix to any word. # TODO: better to form rectangle and then check?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mearly_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m                 \u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mword_trie\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_prefix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import permutations\n",
    "\n",
    "def _construct_trie(dictionary):\n",
    "    \"\"\"Constructs a trie of all words in the given dictionary\"\"\"\n",
    "    class Node:\n",
    "        def __init__(self):\n",
    "            self.children = {}\n",
    "            self.end_of_word = False\n",
    "        def insert(self, word):\n",
    "            if not word:\n",
    "                self.end_of_word = True\n",
    "            else:\n",
    "                c = word[0]\n",
    "                if c not in self.children:\n",
    "                    self.children[c] = Node()\n",
    "                self.children[c].insert(word[1:])\n",
    "        def valid_prefix(self, prefix):\n",
    "            if not prefix:\n",
    "                return True\n",
    "            c = prefix[0]\n",
    "            if c not in self.children:\n",
    "                return False\n",
    "            else:\n",
    "                return self.children[c].valid_prefix(prefix[1:])\n",
    "    \n",
    "    root = Node()\n",
    "    for word in dictionary:\n",
    "        root.insert(word)\n",
    "    \n",
    "    return root \n",
    "                    \n",
    "    \n",
    "def _word_rectangle(width, height, words_by_size, word_tries):\n",
    "    \"\"\"Try to create a word rectangle with the given dimensions\"\"\"\n",
    "    \n",
    "    if width not in words_by_size or height not in words_by_size:\n",
    "        return None\n",
    "    \n",
    "    if len(words_by_size[width]) < height or len(words_by_size[height]) < width:\n",
    "        return None\n",
    "    \n",
    "    print(\"Trying rectangle of size {}(w) x {}(h)\".format(width, height))\n",
    "    \n",
    "    words = words_by_size[width]\n",
    "    if word_trie[h] is None:\n",
    "        word_trie[h] =_construct_trie(words_by_size[height])\n",
    "    word_trie = word_trie[h]\n",
    "    \n",
    "    # Try all permutations of height number of words of length width to see if they\n",
    "    # form a word rectangle. Early exit if non words are found.\n",
    "    for word_idxs in permutations(range(len(words)), height):\n",
    "        if len(word_idxs) != height:\n",
    "            continue\n",
    "            \n",
    "        rectangle = [None] * height\n",
    "        columns = [\"\"] * width\n",
    "        for i, word_idx in enumerate(word_idxs):\n",
    "            word = words[word_idx]\n",
    "            rectangle[i] = word\n",
    "            \n",
    "            # TODO: dont have to start from root everytime\n",
    "            # Early stop if the current prefix in any column is not a \n",
    "            # valid prefix to any word. # TODO: better to form rectangle and then check?\n",
    "            early_stop = False\n",
    "            for j, c in enumerate(word):\n",
    "                columns[j] += c\n",
    "                if not word_trie.valid_prefix(columns[j]):\n",
    "                    early_stop = True\n",
    "                    break\n",
    "            if early_stop:\n",
    "                break\n",
    "        \n",
    "        if not early_stop:\n",
    "            return rectangle\n",
    "    \n",
    "    return None\n",
    "  \n",
    "\n",
    "def word_rectangle(dictionary):\n",
    "    \"\"\"Brute force solution with early stops if a certain combination of words\n",
    "    can not lead to a valid solution\"\"\"\n",
    "    \n",
    "    # Create groupings of word sizes\n",
    "    words_by_size = defaultdict(list)\n",
    "    for word in dictionary:\n",
    "        words_by_size[len(word)].append(word)\n",
    "    max_word_length = max(words_by_size.keys())\n",
    "\n",
    "    # Try to make a word rectangle at decreasing sizes\n",
    "    max_size = max_word_length ** 2\n",
    "    for size in range(max_size, 0, -1):\n",
    "        for width in range(1, size+1):\n",
    "            if size % width != 0:\n",
    "                continue    \n",
    "            height = size // width\n",
    "            wr = _word_rectangle(width, height, words_by_size, [None]*max_word_length)\n",
    "            if wr:\n",
    "                return wr\n",
    "    \n",
    "    return None\n",
    "    \n",
    "import nltk\n",
    "from nltk.corpus import words\n",
    "nltk.download(\"words\")\n",
    "dictionary = set(w.lower() for w in words.words())\n",
    "\n",
    "%time word_rectangle(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
